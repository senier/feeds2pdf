#!/usr/bin/env python3

import argparse
import datetime
import time
import urllib.request
import xml.etree.ElementTree as ET
from email.utils import parsedate
from pathlib import Path
from typing import List, Optional, Set

import html2text
import pandoc
from pandoc.types import (  # pylint: disable=no-name-in-module
    Attr,
    Block,
    Format,
    Header,
    Link,
    Meta,
    MetaBlocks,
    MetaInlines,
    MetaList,
    Pandoc,
    Para,
    RawBlock,
    Space,
    Str,
)
from readability import Document  # type: ignore


def lnk(text: str, target: str) -> Link:
    return Link(NO_ATTR, [Str(text)], (f"#{target}", ""))


MIN_ARTICLE_LEN = 500

HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 "
    "(KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Encoding": "none",
    "Accept-Language": "en-US,en;q=0.8",
    "Connection": "keep-alive",
}

parser = argparse.ArgumentParser(description="Create PDF from RSS feeds")
parser.add_argument(
    "-o", "--output", nargs=1, action="store", type=Path, required=True, help="output file"
)
parser.add_argument(
    "-a",
    "--age",
    nargs=1,
    action="store",
    type=int,
    default=[24],
    help="Maximum age (default: %(default)s)",
)
parser.add_argument("urls", nargs="+", action="store", help="RSS URLs to convert")
args = parser.parse_args()

news = []

for url in args.urls:
    request = urllib.request.Request(url, headers=HEADERS)
    with urllib.request.urlopen(request) as response:
        tree = ET.ElementTree(ET.fromstring(response.read()))
        for channel in tree.findall("./channel"):
            chan_title = channel.find("title")
            assert chan_title is not None
            for item in channel.findall("./item"):
                for child in item:
                    if child.tag == "title":
                        title = child.text
                    elif child.tag == "description":
                        description = child.text
                    elif child.tag == "link":
                        link = child.text
                    elif child.tag == "pubDate":
                        parsed_date = parsedate(child.text)
                        assert parsed_date is not None
                        date = time.mktime(parsed_date)
                    elif child.tag == "guid":
                        guid = child.text
                    elif child.tag in (
                        "author",
                        "category",
                        "comments",
                        "enclosure",
                        "{http://purl.org/dc/elements/1.1/}creator",
                        "{http://purl.org/rss/1.0/modules/content/}encoded",
                        "{http://purl.org/rss/1.0/modules/slash/}comments",
                    ):
                        pass
                    else:
                        print(f"Unknown: {child.tag} - {child.text}")
                news.append((date, chan_title.text, title, description, link, guid))


NO_ATTR: Attr = ("", [], [])
TOP_LINK = Link(NO_ATTR, [Str("[Top]")], ("#top", ""))

content: List[Block] = [Header(1, ("top", [], []), [Str("News")])]
seen: Set[str] = set()
full: List[Block] = []

channels: Set[str] = set()
start: Optional[datetime.datetime] = None
end: Optional[datetime.datetime] = None
has_content: bool = False

for index, (date, chan, title, desc, link, guid) in enumerate(
    reversed(sorted(news, key=lambda e: e[0]))
):
    assert title is not None

    entry_time = datetime.datetime.fromtimestamp(date)
    age = datetime.datetime.now() - entry_time
    if age > datetime.timedelta(hours=args.age[0]):
        continue

    if guid in seen:
        continue

    if guid is not None:
        seen.add(guid)

    assert link is not None
    request = urllib.request.Request(link, headers=HEADERS)
    try:
        with urllib.request.urlopen(request) as response:
            charset = response.headers.get_content_charset() or "utf-8"
            article = Document(response.read().decode(charset))
            summary = article.summary()
            TITLE = article.title()
            converter = html2text.HTML2Text()
            converter.ignore_images = True
            converter.bypass_tables = True
            doc_text = converter.handle(summary)
            if len(doc_text) > MIN_ARTICLE_LEN:
                has_content = True  # pylint: disable=invalid-name
                doc = pandoc.read(doc_text)
                full.append(RawBlock(Format("tex"), "\\newpage"))
                full.append(Header(1, (f"{index}-full", [], []), [lnk(TITLE, str(index))]))
                full.append(RawBlock(Format("tex"), "\\begin{multicols}{2}"))
                full.extend(doc[1])
                full.append(RawBlock(Format("tex"), "\\end{multicols}"))
                full.append(Para([lnk("[Back]", str(index)), TOP_LINK]))
    except (urllib.error.HTTPError, urllib.error.URLError) as e:
        print(f"Error retrieving {link}: {e}")

    if has_content:
        if chan is not None:
            channels.add(chan)
        if start is None or start > entry_time:
            start = entry_time
        if end is None or end < entry_time:
            end = entry_time
        date_str = entry_time.strftime("%a, %Y-%m-%d %H:%M")
        content.append(
            Header(1, (f"{index}", [], []), [Link(NO_ATTR, [Str(title)], (f"#{index}-full", ""))])
        )
        content.append(Para([Str(f"{chan},"), Space(), Str(f"{date_str}"), Space(), TOP_LINK]))
        if desc:
            content.append(RawBlock(Format("tex"), "\\begin{multicols}{2}"))
            content.append(Para([Str(desc)]))
            content.append(RawBlock(Format("tex"), "\\end{multicols}"))

title_str = (
    "News"
    if start is None or end is None
    else f"{start.strftime('%a, %d.%m. %H:%M')} - {end.strftime('%a, %d.%m. %H:%M')}"
)

doc = Pandoc(
    Meta(
        {
            "title": MetaInlines([Str(" | ".join(channels))]),
            "author": MetaInlines([Str(title_str)]),
            "papersize": MetaInlines([Str("a5")]),
            "geometry": MetaInlines([Str("margin=5pt")]),
            "header-includes": MetaList(
                [MetaBlocks([RawBlock(Format("tex"), "\\usepackage{multicol}")])]
            ),
        }
    ),
    content + full,
)
pandoc.write(doc, file=args.output[0], format="pdf", options=["--pdf-engine=xelatex"])
